#### general settings
name: 001_RCANPAx4_DIV2K_60w_2e-5
# name: 001_PANetx4_DF2K_batch32_patch192
use_tb_logger: True
model: sr
distortion: sr
scale: 4
gpu_ids: [7]

#### datasets
datasets:
  train:
    name: DIV2K
    mode: LQGT
    dataroot_GT: /mnt/hyzhao/Documents/datasets/DIV2K_train800/HR_sub480
    dataroot_LQ: /mnt/hyzhao/Documents/datasets/DIV2K_train800/LR_sub120
    
    use_shuffle: true
    n_workers: 6  # per GPU
    batch_size: 16
    GT_size: 192
    use_flip: true
    use_rot: true
    color: RGB
  val:
    name: DIV2K10
    mode: LQGT
    dataroot_GT: /mnt/hyzhao/Documents/datasets/DIV2K_Valid/val_10/HR/X4
    dataroot_LQ: /mnt/hyzhao/Documents/datasets/DIV2K_Valid/val_10/LR/X4

#### network structures
network_G:
  which_model_G: RCAN_PA
  n_resgroups: 10
  n_resblocks: 20
  n_feats: 64
  res_scale: 1
  n_colors: 3
  rgb_range: 1 
  scale: 4
  reduction: ~

#### path
path:
  pretrain_model_G: ../experiments/001_RCANPAx4_DIV2K_40w_5e-5/models/180000_G.pth
#   pretrain_model_G: ../experiments/pretrained_models/RCANPAx4_DIV2K.pth
#   pretrain_model_G: ~
  strict_load: true
  resume_state: ~
#   resume_state: ../experiments/001_RCANPAx4_DIV2K_40w_5e-5/training_state/108000.state

#### training settings: learning rate scheme, loss
train:
  lr_G: !!float 2e-5
#   lr_scheme: MultiStepLR
  lr_scheme: CosineAnnealingLR_Restart
  beta1: 0.9
  beta2: 0.99
  niter: 200000
  warmup_iter: -1  # no warm up
#   lr_steps: [200000, 400000, 600000, 800000, 1000000]
#   restarts: [200000, 400000, 600000, 800000]
#   restart_weights: [0.5, 0.5, 0.5, 0.5]
  T_period: [200000, 200000, 200000, 200000]
  restarts: [200000, 400000, 600000]
  restart_weights: [1, 1, 1]
#   T_period: [100000, 100000, 100000, 100000]
#   restarts: [100000, 200000, 300000]
#   restart_weights: [1, 1, 1]
  eta_min: !!float 1e-7

  pixel_criterion: l1
  pixel_weight: 1.0

  manual_seed: 10
  val_freq: !!float 2e3

#### logger
logger:
  print_freq: 100
  save_checkpoint_freq: !!float 2e3
